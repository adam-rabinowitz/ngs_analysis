import pysam
import numpy as np
import pandas as pd
import multiprocessing
import collections

class coverage(object):

    def __init__(self, bam):
        self.bam = bam
        bamFile = pysam.AlignmentFile(bam)
        self.length = collections.OrderedDict(
            zip(bamFile.references, bamFile.lengths))
        self.name = {bamFile.gettid(x):x for x in bamFile.references}
        bamFile.close()

    def check_intervals(self, intervals):
        for chrom, start, end in intervals:
            # Create interval name
            intName = '{}:{}-{}'.format(chrom, start, end)
            # Check chromsome
            if not isinstance(chrom, str):
                raise TypeError('Interval chromosome must be a string')
            try:
                chromLength = self.length[chrom]
            except KeyError:
                raise ValueError('Invalid chromosome: {}'.format(intName))
            # Check start
            if not isinstance(start, int):
                raise TypeError('Interval starts must be integers')
            if not start >= 0:
                raise ValueError('Invalid start: {}'.format(intName))
            # Check end
            if not isinstance(end, int):
                raise TypeError('Interval ends must be integers')
            if not end <= chromLength:
                raise ValueError('Invalid end: {}'.format(intName))
            # Check interval
            if start >= end:
                raise ValueError('Invalid interval: {}'.format(intName))

    def __extract_intervals(
            self, intervals, conn_out, map_quality, remove_dup
        ):
        # Process connections
        conn_out[0].close()
        # Open bam file and loop through intervals
        bamFile = pysam.AlignmentFile(self.bam)
        for interval in intervals:
            # Send and extract interval data
            conn_out[1].send(interval)
            chrom, start, end = interval
            # Extract reads for interval
            read = None
            for read in bamFile.fetch(chrom, start, end):
                # Skip unmapped reads
                if read.is_unmapped:
                    continue
                # Skip reads below specified mapping quality
                if read.mapping_quality < map_quality:
                    continue
                # Remove duplicate reads if requested
                if remove_dup and read.is_duplicate:
                    continue
                # Extract blocks for read
                for block_start, block_end in read.get_blocks():
                    # Skip blocks not overlapping interval
                    if block_end <= start:
                        continue
                    if block_start >= end:
                        continue
                    # Send overlapping blocks
                    conn_out[1].send((
                        max(start, block_start),
                        min(end, block_end)
                    ))
        # Tidy up
        bamFile.close()
        conn_out[1].close()
    
    def __coverage_change(
            self, intervals, conn_out, map_quality, remove_dup
        ):
        # Process output connection and create input connection
        conn_out[0].close()
        conn_in = multiprocessing.Pipe(False)
        # Start process extracting intervals
        process = multiprocessing.Process(
            target = self.__extract_intervals,
            args = (intervals, conn_in, map_quality, remove_dup)
        )
        process.start()
        conn_in[1].close()
        # Process interval data generated by process
        interval = None
        while True:
            try:
                data = conn_in[0].recv()
            except EOFError:
                if interval is not None:
                    conn_out[1].send((interval, cov_change))
                break
            try:
                start, end = data
                cov_change[start] += 1
                cov_change[end] -= 1
            except ValueError:
                if interval is not None:
                    conn_out[1].send((interval, cov_change))
                interval = data
                cov_change = collections.defaultdict(int)
        # Clean up processes and pipes
        conn_in[0].close()
        process.join()
        conn_out[1].close()
    
    def __coverage_array(
            self, intervals, conn_out, map_quality, remove_dup,
        ):
        # Proces output connection and create input connection
        conn_out[0].close()
        conn_in = multiprocessing.Pipe(False)
        # Start process extracting coverage change
        process = multiprocessing.Process(
            target = self.__coverage_change,
            args = (intervals, conn_in, map_quality, remove_dup)
        )
        process.start()
        conn_in[1].close()
        # Extract data from pipe
        while True:
            try:
                interval, cov_change = conn_in[0].recv()
            except EOFError:
                break
            # Remove zero change items from coverage
            cov_change = {k:v for k,v in cov_change.items() if v}
            # At interval start and end to coverage
            start, end = interval[1:]
            cov_change[start] = cov_change.get(start, 0)
            cov_change[end] = cov_change.get(end, 0)
            # Convert to numpy array, sort, and remove zeros
            cov_array = np.array(cov_change.items(), dtype=np.int32)
            cov_array = cov_array[cov_array[:,0].argsort()] #Is this needed
            conn_out[1].send((interval, cov_array))
        # Clean up pipes and processes
        conn_in[0].close()
        process.join()
        conn_out[1].close()
    
    def __coverage_array_generator(
            self, intervals, map_quality = 0, remove_dup = False
        ):
        # Check arguments
        if not isinstance(map_quality, int) or map_quality < 0:
            raise ValueError('map_qulaity must be non-negative integer')
        if not isinstance(remove_dup, bool):
            raise ValueError('remove_dup must be a bool')
        # Start process building coverage
        conn_in = multiprocessing.Pipe(False)
        process = multiprocessing.Process(
            target = self.__coverage_array,
            args = (intervals, conn_in, map_quality, remove_dup)
        )
        process.start()
        conn_in[1].close()
        # Process coverage generated by process
        while True:
            try:
                cov_array_data = conn_in[0].recv()
            except EOFError:
                break
            yield(cov_array_data)
        # Clean up pipes and processes
        conn_in[0].close()
        process.join()
    
    def bedgraph_file(
            self, bedgraph, intervals, map_quality = 0,
            remove_dup = False
        ):
        # Open output file
        outFile = open(bedgraph, 'w')
        # Create generator and loop through arrays
        for interval, array in self.__coverage_array_generator(
                intervals, map_quality, remove_dup
            ):
            # Calculate coverage
            chrom = interval[0]
            coverage = np.cumsum(array[:,1])
            if coverage[-1] != 0:
                raise ValueError('Error in coverage calculations')
            for i in range(array.shape[0] - 1):
                outLine = '{}\t{}\t{}\t{}\n'.format(
                    chrom,
                    array[i, 0],
                    array[i + 1, 0],
                    coverage[i]
                )
                outFile.write(outLine)
        outFile.close()
    
    def histogram(
            self, intervals, max_cov = 200, map_quality = 0, remove_dup = False
        ):
        # Create ordered dictionary of results
        histogram = collections.OrderedDict()
        for x in range(max_cov + 1):
            histogram[x] = 0
        # Create generator and loop through arrays
        for interval, array in self.__coverage_array_generator(
                intervals, map_quality, remove_dup
            ):
            # Calculate lengths and coverage and add to histogram
            lengths = np.diff(array[:,0])
            coverage = np.cumsum(array[:,1])
            if coverage[-1] != 0:
                raise ValueError('Error in coverage calculations')
            for c, l in zip(coverage[:-1], lengths):
                histogram[min(c, max_cov)] += l
        # Return data
        return(histogram)
    
    def mean_coverage(
            self, intervals, map_quality = 0, remove_dup = False,
            check_intervals = True
        ):
        # Check intervals
        if check_intervals:
            self.check_intervals(intervals)
        # Create output list
        meanList = []
        # Create generator and loop through arrays
        for interval, array in self.__coverage_array_generator(
                intervals, map_quality, remove_dup
            ):
            # Calculate lengths and coverage
            lengths = np.diff(array[:,0])
            coverage = np.cumsum(array[:,1])
            if coverage[-1] != 0:
                raise ValueError('Error in coverage calculations')
            # Calculate mean coverage
            meanCov = np.average(coverage[:-1], weights=lengths)
            meanList.append(meanCov)
        # Clean up processes and pipes
        return(meanList)
